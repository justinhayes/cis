# Specify server locations in a SOLR_LOCATOR variable; used later in variable substitutions:
SOLR_LOCATOR : {
  # Name of solr collection
  collection : ciscollection

  # ZooKeeper ensemble
  zkHost : "hadoop0:2181/solr"

  # The maximum number of documents to send to Solr per network batch (throughput knob)
  # batchSize : 100
}

morphlines : [
  {
    id : normalizeHttpdLog
    importCommands : ["com.cloudera.**", "org.apache.solr.**"]

    commands : [
     #{ logInfo { format : "httpd input record {}", args : ["@{}"] } }
     
     # Read the CSV data
     {
        #192.168.48.60 - - [10/Jul/2012:16:15:06 -0400] "GET /shuttle/missions/sts-71/sts-71-day-11-highlights.html HTTP/1.0" 200 6626
        #198.83.19.44 - - [12/Aug/2012:12:37:47 -0400] "GET /shuttle/resources/orbiters/endeavour.html HTTP/1.0" 200 6168
        #192.168.34.72 - - [01/Jul/2012:11:32:00 -0400] "GET /icons/unknown.xbm " 200 515
        #192.168.45.49 - - [03/Aug/2012:17:01:19 -0400] "GET /elv/new01.gif> " 404 -
        readCSV {
          separator : " "
          columns : ["srcip","a","b","eventts","tz","verb","resource","proto","code","len"]
          ignoreFirstLine : false
          trim : false
          charset : UTF-8
        }
      }
      
      # Build raw field and then clean up unnecessary fields
      {
         java {
            imports : "import java.util.*; import java.lang.StringBuilder;"
            code: """
               //rebuild the entire raw record
               StringBuilder val = new StringBuilder();
               String[] inputFields = new String[]{"srcip","a","b","eventts","tz","verb","resource","proto","code","len"};
               for(String inputField : inputFields) {
                   val.append(record.getFirstValue(inputField)).append(" ");
               }
               record.put("raw", val.toString().trim());
               
               //remove unneeded fields from the parsed version
               String[] inputFieldsToRemove = new String[]{"a","b","tz"};
               for(String inputFieldToRemove : inputFieldsToRemove) {
                   record.removeAll(inputFieldToRemove);
               }
               
               //add some empty fields that are needed in the final record
               record.put("type", "httpd");
               record.put("dstip", "");
               record.put("srcport", "");
               record.put("dstport", "");
               record.put("outlier", "-1");
               
               return child.process(record);
            """
         }
      }
      
      # Strip leading [ from the ts field then convert it to 'yyyy-mm-dd hh:mm:ss'
      { 
         findReplace { 
            field : eventts
            pattern : "["
            replacement : ""
         }
      }
      { 
         convertTimestamp { 
            field : eventts
            inputFormats : ["dd/MMM/yyyy:HH:mm:ss"]
            inputTimezone : UTC
            outputFormat : "yyyy-MM-dd HH:mm:ss"
            outputTimezone : UTC
         } 
      }
      
      # Add the current time
      {
         addCurrentTime {
            field: ts
         }
      }
      { 
         convertTimestamp { 
            field : ts
            inputFormats : ["unixTimeInMillis"]
            inputTimezone : UTC
            outputFormat : "yyyy-MM-dd HH:mm:ss"
            outputTimezone : UTC
         } 
      }
      
      # Strip the " from verb field
      { 
         findReplace { 
            field : verb
            pattern : "\""
            replacement : ""
         }
      }
      
      # Strip the " from proto field
      { 
         findReplace { 
            field : proto
            pattern : "\""
            replacement : ""
         }
      }
      
      # Set some additional values, some of which have defaults, others of which are to remain empty
      #{
      #   addValues {
      #      type : "httpd"
      #      dstip : ""
      #      srcport : ""
      #      dstport : ""
      #   }
      #}
      
      # Put things in order in a single, tab-separated value
      #["ts","raw","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"]
      {
         java {
            imports : "import java.util.*; import java.lang.StringBuilder; import com.cloudera.solutions.cis.flume.PartitionHelper;"
            code: """
               //set the len field to the empty string if it is '-'
               String len = record.getFirstValue("len").toString();
               len = "-".equals(len) ? "" : len;
               
               //make sure the protocol is not empty
               String proto = record.getFirstValue("proto").toString();
               proto = (proto == null || "".equals(proto)) ? "unknown" : proto;
               
               StringBuilder val = new StringBuilder();
               String[] inputFields = new String[]{"ts","raw","eventts","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"};
               for(String inputField : inputFields) {
                   if (inputField.equals("len")) {
                       val.append(len).append("\t");
                   } else if (inputField.equals("proto")) {
                       val.append(proto).append("\t");
                   } else {
                       val.append(record.getFirstValue(inputField)).append("\t");
                   }
               }
               
               //validate that val contains a valid record; if not, then don't add a record field for it, ie:
               //	must have correct number of tabs
               //	each field must be of the correct type
               //(ts TIMESTAMP, raw STRING, eventts TIMESTAMP, type STRING, verb STRING, resource STRING, code INT, len INT, srcip STRING, dstip STRING, srcport INT, dstport INT, proto STRING, outlier INT)
               boolean valid = true;
               try {
                   Integer.parseInt(record.getFirstValue("code").toString());
               } catch (Exception ex) {
                   valid = false;
               }
               
               val.deleteCharAt(val.length() - 1); //trim off the trailing "\t"
               if (valid) {
                   record.put("record", val.toString().trim());
                   record.put("hourPartition", PartitionHelper.getHourPartition(System.currentTimeMillis()));
               } else {
                   record.put("record2", val.toString().trim());
               }
               
               //now remove the original fields
               for(String inputField : inputFields) {
                   record.removeAll(inputField);
               }
               
               return child.process(record);
            """
         }
      }
      
      #{ logInfo { format : "output record {}", args : ["@{}"] } }
    ]
  }
  
  {
    id : normalizeIptablesLog
    importCommands : ["com.cloudera.**", "org.apache.solr.**"]

    commands : [
     
     # Read the CSV data
     {
        #Jul  14 12:44:51 debian kernel: IN=ra0 OUT= MAC=00:17:9a:0a:f6:44:00:08:5c:00:00:01:08:00 SRC=192.168.16.29 DST=192.168.102.181 LEN=60 TOS=0x00 PREC=0x00 TTL=51 ID=18374 DF PROTO=udp SPT=40557 DPT=51 WINDOW=5840 RES=0x00 SYN URGP=0
        readCSV {
          separator : " "
          columns : ["mon","extraspace","day","time","os","program","in","out","mac","srcip","dstip","len","tos","prec","ttl","id","df","proto","srcport","dstport","window","res","syn","urgp"]
          ignoreFirstLine : false
          trim : false
          charset : UTF-8
        }
      }
      
      # Build raw field and then clean up unnecessary fields
      {
         java {
            imports : "import java.util.*; import java.lang.StringBuilder;"
            code: """
               //rebuild the entire raw record
               StringBuilder val = new StringBuilder();
               String[] inputFields = new String[]{"mon","day","time","os","program","in","out","mac","srcip","dstip","len","tos","prec","ttl","id","df","proto","srcport","dstport","window","res","syn","urgp"};
               for(String inputField : inputFields) {
                   val.append(record.getFirstValue(inputField)).append(" ");
               }
               record.put("raw", val.toString().trim());
               
               //create the ts field by concatenating the year, month, day, and time fields to match this format: dd/MMM/yyyy:HH:mm:ss
               String year = "2014"; //TODO make dynamic
               record.put("eventts", record.getFirstValue("day") + "/" + record.getFirstValue("mon") + "/" + year + ":" + record.getFirstValue("time"));
               
               //Take everything after the "=" in the following fields: srcip, dstip, len, proto, srcport, dstport
               //TODO do this in a substr command?
               record.replaceValues("srcip", record.getFirstValue("srcip").toString().substring(record.getFirstValue("srcip").toString().indexOf("=")+1));
               record.replaceValues("dstip", record.getFirstValue("dstip").toString().substring(record.getFirstValue("dstip").toString().indexOf("=")+1));
               record.replaceValues("len", record.getFirstValue("len").toString().substring(record.getFirstValue("len").toString().indexOf("=")+1));
               record.replaceValues("proto", record.getFirstValue("proto").toString().substring(record.getFirstValue("proto").toString().indexOf("=")+1));
               record.replaceValues("srcport", record.getFirstValue("srcport").toString().substring(record.getFirstValue("srcport").toString().indexOf("=")+1));
               record.replaceValues("dstport", record.getFirstValue("dstport").toString().substring(record.getFirstValue("dstport").toString().indexOf("=")+1));
               
               //remove unneeded fields from the parsed version
               String[] inputFieldsToRemove = new String[]{"mon","extraspace","day","time","os","program","in","out","mac","tos","prec","ttl","id","df","window","res","syn","urgp"};
               for(String inputFieldToRemove : inputFieldsToRemove) {
                   record.removeAll(inputFieldToRemove);
               }
               
               //add some fields that are needed in the final record
               record.put("type", "iptables");
               record.put("verb", "");
               record.put("resource", "");
               record.put("code", "");
               record.put("outlier", "-1");
               
               return child.process(record);
            """
         }
      }
      
      # Convert ts field to 'yyyy-mm-dd hh:mm:ss'
      { 
         convertTimestamp { 
            field : eventts
            inputFormats : ["dd/MMM/yyyy:HH:mm:ss"]
            inputTimezone : UTC
            outputFormat : "yyyy-MM-dd HH:mm:ss"
            outputTimezone : UTC
         } 
      }
      
      # Add the current time
      {
         addCurrentTime {
            field: ts
         }
      }
      { 
         convertTimestamp { 
            field : ts
            inputFormats : ["unixTimeInMillis"]
            inputTimezone : UTC
            outputFormat : "yyyy-MM-dd HH:mm:ss"
            outputTimezone : UTC
         } 
      }
      
      # Put things in order in a single, tab-separated value
      #["ts","raw","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"]
      {
         java {
            imports : "import java.util.*; import java.lang.StringBuilder; import com.cloudera.solutions.cis.flume.PartitionHelper;"
            code: """
               StringBuilder val = new StringBuilder();
               String[] inputFields = new String[]{"ts","raw","eventts","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"};
               for(String inputField : inputFields) {
                   val.append(record.getFirstValue(inputField)).append("\t");
                   record.removeAll(inputField);
               }
               val.deleteCharAt(val.length() - 1); //trim off the trailing "\t"
               record.put("record", val.toString().trim());
               record.put("hourPartition", PartitionHelper.getHourPartition(System.currentTimeMillis()));
               
               return child.process(record);
            """
         }
      }
      
      #{ logInfo { format : "output record {}", args : ["@{}"] } }
    ]
  }
  
  {
    id : normalizeKddLog
    importCommands : ["com.cloudera.**", "org.apache.solr.**"]

    commands : [
     
     # Read the CSV data
     {
        #0,udp,private,SF,105,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,1,1,1.00,0.00,1.00,0.00,0.00,0.00,0.00,0.00
        #Fields that overlap with the other sources are proto and len
        readCSV {
          separator : ","
          columns : ["duration","transport","proto","flag","src_bytes","len","land","wrong_fragment","urgent","hot","num_failed_logins","logged_in","num_compromised","root_shell","su_attempted","num_root","num_file_creations","num_shells","num_access_files","num_outbound_cmds","is_host_login","is_guest_login","count","srv_count","serror_rate","srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate","diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count","dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate","dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate","dst_host_rerror_rate","dst_host_srv_rerror_rate"]
          ignoreFirstLine : false
          trim : false
          charset : UTF-8
        }
      }
      
      # Build raw field and then clean up unnecessary fields
      {
         java {
            imports : "import java.util.*; import java.lang.StringBuilder;"
            code: """
               //rebuild the entire raw record
               StringBuilder val = new StringBuilder();
               String[] inputFields = new String[]{"duration","transport","proto","flag","src_bytes","len","land","wrong_fragment","urgent","hot","num_failed_logins","logged_in","num_compromised","root_shell","su_attempted","num_root","num_file_creations","num_shells","num_access_files","num_outbound_cmds","is_host_login","is_guest_login","count","srv_count","serror_rate","srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate","diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count","dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate","dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate","dst_host_rerror_rate","dst_host_srv_rerror_rate"};
               List fieldsToKeep = Arrays.asList(new String[]{"proto","len"});
               for(String inputField : inputFields) {
                   val.append(record.getFirstValue(inputField)).append(",");
                   if (!fieldsToKeep.contains(inputField)) {
                       record.removeAll(inputField);
                   }
               }
               val.deleteCharAt(val.length() - 1); //trim off the trailing ","
               record.put("raw", val.toString().trim());
               
               //add some fields that are needed in the final record
               record.put("type", "kdd");
               record.put("verb", "");
               record.put("resource", "");
               record.put("code", "");
               record.put("srcip", "");
               record.put("dstip", "");
               record.put("srcport", "");
               record.put("dstport", "");
               
               //get the outlier field from the OryxDistance interceptor
               //record.put("outlier", record.getFirstValue("outlier"));
               
               return child.process(record);
            """
         }
      }
      
      #{
      #   addValues {
      #      outlier : "@{outlier}"
      #   }
      #}

      
      # Add the current time and eventts fields
      {
         addCurrentTime {
            field: eventts
         }
      }
      {
         addCurrentTime {
            field: ts
         }
      }
      { 
         convertTimestamp { 
            field : eventts
            inputFormats : ["unixTimeInMillis"]
            inputTimezone : UTC
            outputFormat : "yyyy-MM-dd HH:mm:ss"
            outputTimezone : UTC
         } 
      }
      { 
         convertTimestamp { 
            field : ts
            inputFormats : ["unixTimeInMillis"]
            inputTimezone : UTC
            outputFormat : "yyyy-MM-dd HH:mm:ss"
            outputTimezone : UTC
         }
      }
      
      # Put things in order in a single, tab-separated value
      #["ts","raw","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"]
      {
         java {
            imports : "import java.util.*; import java.lang.StringBuilder; import com.cloudera.solutions.cis.flume.PartitionHelper;"
            code: """
               StringBuilder val = new StringBuilder();
               String[] inputFields = new String[]{"ts","raw","eventts","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"};
               for(String inputField : inputFields) {
                   val.append(record.getFirstValue(inputField)).append("\t");
                   record.removeAll(inputField);
               }
               val.deleteCharAt(val.length() - 1); //trim off the trailing "\t"
               
               record.put("record", val.toString().trim());
               record.put("hourPartition", PartitionHelper.getHourPartition(System.currentTimeMillis()));
               
               for(String inputField : inputFields) {
                   record.removeAll(inputField);
               }
               
               //System.out.println("at end, ***record=" + record.getFirstValue("record").toString());
               
               return child.process(record);
            """
         }
      }
      
      #{ logInfo { format : "output record {}", args : ["@{}"] } }
    ]
  }
  
  {
    id : solrIndexer
    importCommands : ["com.cloudera.**", "org.apache.solr.**"]

    commands : [
      #{ logInfo { format : "solr input record {}", args : ["@{}"] } }
     
      # Parse the TSV data in the "record" field
      # TODO use this if we are using a newer morphlines version (>= 0.9); if not, must hack it
      #{
      #   split {
      #      inputField : record
      #      outputFields : [ts,raw,eventts,type,verb,resource,code,len,srcip,dstip,srcport,dstport,proto]
      #      separator : "\t"
      #      isRegex : false
      #      addEmptyStrings : true 
      #      trim : true
      #   }
      #}
      {
         java {
            imports : "import java.util.*;"
            code: """
               String[] fields = record.getFirstValue("record").toString().split("\t");
               String[] fieldNames = {"ts","raw","eventts","type","verb","resource","code","len","srcip","dstip","srcport","dstport","proto","outlier"};
               if (fields.length != fieldNames.length) {
                  System.out.println("Ignoring record that didn't parse properly: " + record.getFirstValue("record").toString());
                  System.out.println("  fields.length=" + fields.length + "; should be " + fieldNames.length);
               } else {
                  for (int i = 0; i < fieldNames.length; i++) {
                     if (fields[i] != null && !"".equals(fields[i])) {
                        record.put(fieldNames[i], fields[i]);
                     }
                  }
               }
               
               record.removeAll("record");
               
               return child.process(record);
            """
         }
      }
      
      # Add a unique id field
      {
         generateUUID {
            field : id
         }
      }
      
      #{ logInfo { format : "post parse record {}", args : ["@{}"] } }
      
      # convert timestamp field to native Solr timestamp format
      # e.g. 2012-09-06T07:14:34Z to 2012-09-06T07:14:34.000Z
      {
        convertTimestamp {
          field : ts
          inputFormats : ["yyyy-MM-dd HH:mm:ss"]
          inputTimezone : UTC
#          outputFormat : "yyyy-MM-dd'T'HH:mm:ss.SSSZ"                                 
          outputTimezone : UTC
        }
      }
      {
        convertTimestamp {
          field : eventts
          inputFormats : ["yyyy-MM-dd HH:mm:ss"]
          inputTimezone : UTC
#          outputFormat : "yyyy-MM-dd'T'HH:mm:ss.SSSZ"                                 
          outputTimezone : UTC
        }
      }

      #{ logInfo { format : "post ts conversion record {}", args : ["@{}"] } }

      # Command that sanitizes record fields that are unknown to Solr schema.xml by either 
      # deleting them (renameToPrefix is absent or a zero length string), or by moving them to a
      # field prefixed with the given renameToPrefix (e.g. renameToPrefix = "ignored_" to use 
      # typical dynamic Solr fields).
      #
      # Recall that Solr throws an exception on any attempt to load a document that contains a 
      # field that isn't specified in schema.xml.
      {
        sanitizeUnknownSolrFields {
          # Location from which to fetch Solr schema
          solrLocator : ${SOLR_LOCATOR}

          # renameToPrefix : "ignored_"
        }
      }

      # log the record at DEBUG level to SLF4J
      #{ logInfo { format : "post sanitize record {}", args : ["@{}"] } }

      # load the record into a Solr server or MapReduce Reducer.
      {
        loadSolr {
          solrLocator : ${SOLR_LOCATOR}
        }
      }
      
    ]
  }
]